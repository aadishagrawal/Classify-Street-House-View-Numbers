{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                ASSIGNMENT NEURAL NETWORK - AADISH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Part 1 - Data fetching and understand the train/val/test splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Load Dataset and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras import regularizers\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5f = h5py.File('SVHN_single_grey1.h5', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = h5f['X_train'][:]\n",
    "y_train1 = h5f['y_train'][:]\n",
    "X_test = h5f['X_test'][:]\n",
    "y_test1 = h5f['y_test'][:]\n",
    "\n",
    "h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 32, 32)\n",
      "(42000,)\n",
      "(18000, 32, 32)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "print (X_train.shape)\n",
    "print (y_train1.shape)\n",
    "print (X_test.shape)\n",
    "print (y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set classes\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([4186, 4172, 4197, 4281, 4188, 4232, 4168, 4192, 4188, 4196]))\n",
      "test set classes\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([1814, 1828, 1803, 1719, 1812, 1768, 1832, 1808, 1812, 1804]))\n"
     ]
    }
   ],
   "source": [
    "# 0-9 classes which seems to be equally distributed along the datasets\n",
    "import numpy as np\n",
    "print('train set classes')\n",
    "print(np.unique(y_train1, return_index=False, return_inverse=False, return_counts=True, axis=None))\n",
    "print('test set classes')\n",
    "print(np.unique(y_test1, return_index=False, return_inverse=False, return_counts=True, axis=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image: [2 6 7 4 4 0 3 0 7 3]\n"
     ]
    }
   ],
   "source": [
    "# visualizing the first 10 images in the dataset and their labels\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 1))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.imshow(X_train[i], cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "print('label for each of the above image: %s' % (y_train1[0:10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 1024)\n",
      "(18000, 1024)\n"
     ]
    }
   ],
   "source": [
    "# reshaping X data: (n, 3224, 32) => (n, 10)\n",
    "X_train = X_train.reshape((X_train.shape[0], -1))\n",
    "X_test = X_test.reshape((X_test.shape[0], -1))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 10)\n",
      "(18000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One Hot Encoding of target Variable\n",
    "y_train1 = to_categorical(y_train1)\n",
    "y_test1 = to_categorical(y_test1)\n",
    "print(y_train1.shape)\n",
    "print(y_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Part2 - Implement and apply a deep neural network classifier including (feedforward neural network, RELU, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                            Basic NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Activation, Dense\n",
    "from keras import optimizers\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(200, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(60, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30, kernel_initializer='he_normal'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)\n",
    "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/aadishagrawal/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 7s 155us/step - loss: 2.2433 - accuracy: 0.1597\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 6s 146us/step - loss: 1.9090 - accuracy: 0.3434\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 1.5302 - accuracy: 0.4991\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 6s 149us/step - loss: 1.3295 - accuracy: 0.5744\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 7s 156us/step - loss: 1.2189 - accuracy: 0.6139\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 7s 161us/step - loss: 1.1351 - accuracy: 0.6431\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 7s 165us/step - loss: 1.0727 - accuracy: 0.6657\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 7s 168us/step - loss: 1.0265 - accuracy: 0.6806\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 7s 171us/step - loss: 0.9873 - accuracy: 0.6926\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 7s 174us/step - loss: 0.9533 - accuracy: 0.7036\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train1, batch_size = 32, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 1s 60us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6268333196640015\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Part 3 - Implement batch normalization for training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchNorm_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(200, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(60, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr = 0.01)\n",
    "    model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 18s 418us/step - loss: 1.8816 - accuracy: 0.3501\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 16s 375us/step - loss: 1.3144 - accuracy: 0.5748\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 16s 375us/step - loss: 1.1130 - accuracy: 0.6438\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 16s 374us/step - loss: 1.0179 - accuracy: 0.6759\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 16s 380us/step - loss: 0.9419 - accuracy: 0.6998\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 16s 381us/step - loss: 0.8829 - accuracy: 0.7185\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 16s 381us/step - loss: 0.8406 - accuracy: 0.7341\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 17s 394us/step - loss: 0.7991 - accuracy: 0.7455\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 1624s 39ms/step - loss: 0.7708 - accuracy: 0.7525\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 18s 426us/step - loss: 0.7409 - accuracy: 0.7633\n"
     ]
    }
   ],
   "source": [
    "model = BatchNorm_model()\n",
    "history = model.fit(X_train, y_train1, batch_size = 32, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 110us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5246666669845581\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                Adding dropout normatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(200, input_shape = (1024, ), kernel_initializer='he_normal', name='Layer_1'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    " #  model.add(Dropout(0.4))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal',name='Layer_2'))\n",
    "#   model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(60, kernel_initializer='he_normal',name='Layer_3'))\n",
    " #  model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "  # model.add(Dropout(0.4))\n",
    "    model.add(Dense(30, kernel_initializer='he_normal', name='Layer_4'))\n",
    "#   model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal', name='Layer_5'))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr = 0.01)\n",
    "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "42000/42000 [==============================] - 24s 570us/step - loss: 1.9800 - accuracy: 0.2675\n",
      "Epoch 2/10\n",
      "42000/42000 [==============================] - 24s 569us/step - loss: 1.5258 - accuracy: 0.4843\n",
      "Epoch 3/10\n",
      "42000/42000 [==============================] - 25s 592us/step - loss: 1.3306 - accuracy: 0.5665\n",
      "Epoch 4/10\n",
      "42000/42000 [==============================] - 26s 618us/step - loss: 1.2230 - accuracy: 0.6114\n",
      "Epoch 5/10\n",
      "42000/42000 [==============================] - 23s 545us/step - loss: 1.1521 - accuracy: 0.6393\n",
      "Epoch 6/10\n",
      "42000/42000 [==============================] - 23s 548us/step - loss: 1.0945 - accuracy: 0.6611\n",
      "Epoch 7/10\n",
      "42000/42000 [==============================] - 23s 553us/step - loss: 1.0449 - accuracy: 0.6718\n",
      "Epoch 8/10\n",
      "42000/42000 [==============================] - 24s 560us/step - loss: 1.0123 - accuracy: 0.6886\n",
      "Epoch 9/10\n",
      "42000/42000 [==============================] - 23s 559us/step - loss: 0.9669 - accuracy: 0.7018\n",
      "Epoch 10/10\n",
      "42000/42000 [==============================] - 24s 566us/step - loss: 0.9411 - accuracy: 0.7087\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "model = mlp_model()\n",
    "history = model.fit(X_train, y_train1, batch_size = 32, epochs = 10, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000/18000 [==============================] - 2s 94us/step\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6391111016273499\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                    HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def train_and_test_loop(iterations, lr, Lambda, verb=True):\n",
    "\n",
    "    ## hyperparameters\n",
    "    iterations = iterations\n",
    "    learning_rate = lr\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(200, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(60, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(30, kernel_initializer='he_normal'))\n",
    "    model.add(BatchNormalization()) \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(10, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "    # Compile model\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train1, epochs=iterations, batch_size=1000, verbose= 1)\n",
    "    score = model.evaluate(X_train, y_train1, verbose=0)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 145us/step - loss: 1.8819 - accuracy: 0.3706\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.1171 - accuracy: 0.6443\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.9031 - accuracy: 0.7176\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.7793 - accuracy: 0.7588\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.7192 - accuracy: 0.7776\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.6518 - accuracy: 0.8010\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.6122 - accuracy: 0.8130\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.5716 - accuracy: 0.8258\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.5468 - accuracy: 0.8332\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.5130 - accuracy: 0.8436\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4824 - accuracy: 0.8546\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 4s 106us/step - loss: 0.4642 - accuracy: 0.8589\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 4s 88us/step - loss: 0.4381 - accuracy: 0.8690\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.4228 - accuracy: 0.8730\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4059 - accuracy: 0.8765\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3910 - accuracy: 0.8828\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3817 - accuracy: 0.8848\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3717 - accuracy: 0.8885\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3576 - accuracy: 0.8930\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3334 - accuracy: 0.9002\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3240 - accuracy: 0.9034\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 0.3048 - accuracy: 0.9101\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3006 - accuracy: 0.9108\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 0.2985 - accuracy: 0.9128\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3137 - accuracy: 0.9063\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.2834 - accuracy: 0.9164\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.2699 - accuracy: 0.9221\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.2547 - accuracy: 0.9269\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.2475 - accuracy: 0.9287\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 0.2385 - accuracy: 0.9316\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.2370 - accuracy: 0.9307\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.2377 - accuracy: 0.9308\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.2241 - accuracy: 0.9350\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.2201 - accuracy: 0.9363\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.2085 - accuracy: 0.9404\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.2034 - accuracy: 0.9429\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 0.1897 - accuracy: 0.9467\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.2043 - accuracy: 0.9414\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.1891 - accuracy: 0.9474\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.1852 - accuracy: 0.9479\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.1905 - accuracy: 0.9449\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.1709 - accuracy: 0.9529\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.1721 - accuracy: 0.9517\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.1696 - accuracy: 0.9524\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 0.1714 - accuracy: 0.9519\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.1631 - accuracy: 0.9551\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.1603 - accuracy: 0.9553\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 0.1510 - accuracy: 0.9590\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 4s 94us/step - loss: 0.1479 - accuracy: 0.9600\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 4s 97us/step - loss: 0.1425 - accuracy: 0.9614\n",
      "Try 1/100: Best_val_acc: [0.9252436982790629, 0.7660475969314575], lr: 0.09009150715856748, Lambda: 0.000512485482169287\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 2.6859 - accuracy: 0.1063\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 2.4786 - accuracy: 0.1330\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 2.3419 - accuracy: 0.1625\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 2.2466 - accuracy: 0.1934\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 2.1710 - accuracy: 0.2266\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 2.1056 - accuracy: 0.2603\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 2.0461 - accuracy: 0.2902\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.9912 - accuracy: 0.3190\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.9407 - accuracy: 0.3425\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.8930 - accuracy: 0.3663\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 1.8486 - accuracy: 0.3880\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 1.8069 - accuracy: 0.4085\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.7675 - accuracy: 0.4255\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.7303 - accuracy: 0.4424\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.6941 - accuracy: 0.4596\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.6599 - accuracy: 0.4741\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.6266 - accuracy: 0.4890\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.5946 - accuracy: 0.5036\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.5639 - accuracy: 0.5142\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.5338 - accuracy: 0.5285\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.5049 - accuracy: 0.5399\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.4772 - accuracy: 0.5505\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.4500 - accuracy: 0.5599\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.4236 - accuracy: 0.5719\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.3986 - accuracy: 0.5817\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.3743 - accuracy: 0.5896\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.3507 - accuracy: 0.5983\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.3276 - accuracy: 0.6064\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.3061 - accuracy: 0.6131\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.2857 - accuracy: 0.6201\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.2644 - accuracy: 0.6243\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.2446 - accuracy: 0.6323\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.2249 - accuracy: 0.6384\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.2070 - accuracy: 0.6444\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.1893 - accuracy: 0.6483\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.1719 - accuracy: 0.6547\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.1552 - accuracy: 0.6573\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.1389 - accuracy: 0.6626\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.1231 - accuracy: 0.6677\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.1078 - accuracy: 0.6705\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.0925 - accuracy: 0.6763\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.0796 - accuracy: 0.6779\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.0645 - accuracy: 0.6823\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.0517 - accuracy: 0.6868\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.0394 - accuracy: 0.6890\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.0259 - accuracy: 0.6923\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.0135 - accuracy: 0.6974\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.0019 - accuracy: 0.6998\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.9901 - accuracy: 0.7034\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.9802 - accuracy: 0.7073\n",
      "Try 2/100: Best_val_acc: [0.9990749211765471, 0.6994761824607849], lr: 0.0007429590862154917, Lambda: 0.0002572739345083709\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 145us/step - loss: 2.0820 - accuracy: 0.2990\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 1.3505 - accuracy: 0.5928\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.0482 - accuracy: 0.6875\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.9117 - accuracy: 0.7285\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 4s 99us/step - loss: 0.8142 - accuracy: 0.7601\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.7489 - accuracy: 0.7809\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.6989 - accuracy: 0.7970\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 4s 94us/step - loss: 0.6530 - accuracy: 0.8124\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.6160 - accuracy: 0.8232\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.5880 - accuracy: 0.8314\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.5730 - accuracy: 0.8345\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.5325 - accuracy: 0.8467\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.5192 - accuracy: 0.8507\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4998 - accuracy: 0.8569\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4796 - accuracy: 0.8639\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4668 - accuracy: 0.8691\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4512 - accuracy: 0.8729\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4257 - accuracy: 0.8804\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4196 - accuracy: 0.8823\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.3996 - accuracy: 0.8883\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.4045 - accuracy: 0.8859\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.3809 - accuracy: 0.8956\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.3681 - accuracy: 0.8987\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.3634 - accuracy: 0.9012\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.3494 - accuracy: 0.9048\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.3500 - accuracy: 0.9043\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.3329 - accuracy: 0.9097\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.3134 - accuracy: 0.9171\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.3142 - accuracy: 0.9153\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.3060 - accuracy: 0.9182\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2976 - accuracy: 0.9198\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2963 - accuracy: 0.9219\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.2942 - accuracy: 0.9195\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.2850 - accuracy: 0.9241\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2724 - accuracy: 0.9299\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2613 - accuracy: 0.9316\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2427 - accuracy: 0.9393\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.2427 - accuracy: 0.9381\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2472 - accuracy: 0.9368\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.2345 - accuracy: 0.9414\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.2214 - accuracy: 0.9448\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2416 - accuracy: 0.9372\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2483 - accuracy: 0.9350\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2174 - accuracy: 0.9450\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.2164 - accuracy: 0.9465\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.2117 - accuracy: 0.9474\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.2020 - accuracy: 0.9516\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.2028 - accuracy: 0.9502\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.1948 - accuracy: 0.9535\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 0.1929 - accuracy: 0.9533\n",
      "Try 3/100: Best_val_acc: [0.8431001652990069, 0.7695237994194031], lr: 0.03403254179696349, Lambda: 0.0015999257602334386\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 147us/step - loss: 2.4611 - accuracy: 0.1514\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 3s 79us/step - loss: 2.0447 - accuracy: 0.2846\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.7868 - accuracy: 0.4156\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.5752 - accuracy: 0.5049\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.4089 - accuracy: 0.5670\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 1.2793 - accuracy: 0.6110\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.1745 - accuracy: 0.6463\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.0859 - accuracy: 0.6751\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 1.0124 - accuracy: 0.6974\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 4s 89us/step - loss: 0.9532 - accuracy: 0.7126\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 4s 90us/step - loss: 0.9059 - accuracy: 0.7268\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 5s 119us/step - loss: 0.8620 - accuracy: 0.7379\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 4s 104us/step - loss: 0.8237 - accuracy: 0.7493\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.7862 - accuracy: 0.7614\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 4s 94us/step - loss: 0.7541 - accuracy: 0.7718\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.7286 - accuracy: 0.7798\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.7041 - accuracy: 0.7870\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.6769 - accuracy: 0.7947\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.6557 - accuracy: 0.8007\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.6420 - accuracy: 0.8060\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.6186 - accuracy: 0.8108\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.6107 - accuracy: 0.8143\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.5923 - accuracy: 0.8220\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.5807 - accuracy: 0.8239\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 5s 110us/step - loss: 0.5643 - accuracy: 0.8298\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 4s 99us/step - loss: 0.5522 - accuracy: 0.8326\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 4s 96us/step - loss: 0.5417 - accuracy: 0.8361\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 0.5241 - accuracy: 0.8430\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 0.5110 - accuracy: 0.8478\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.4998 - accuracy: 0.8510\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.4911 - accuracy: 0.8545\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4812 - accuracy: 0.8578\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4698 - accuracy: 0.8614\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 0.4656 - accuracy: 0.8622\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4503 - accuracy: 0.8682\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4464 - accuracy: 0.8693\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4423 - accuracy: 0.8696\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4289 - accuracy: 0.8740\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4190 - accuracy: 0.8777\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 0.4162 - accuracy: 0.8786\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.4010 - accuracy: 0.8825\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3934 - accuracy: 0.8859\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.3973 - accuracy: 0.8840\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3823 - accuracy: 0.8889\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3788 - accuracy: 0.8890\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3779 - accuracy: 0.8902\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3647 - accuracy: 0.8944\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3607 - accuracy: 0.8951\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3591 - accuracy: 0.8976\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 4s 107us/step - loss: 0.3504 - accuracy: 0.8991\n",
      "Try 4/100: Best_val_acc: [0.8637775821118128, 0.7576904892921448], lr: 0.004962954950404333, Lambda: 0.0002432740622477389\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 152us/step - loss: 2.6398 - accuracy: 0.1035\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 4s 90us/step - loss: 2.5577 - accuracy: 0.1171\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 2.4901 - accuracy: 0.1307\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 4s 88us/step - loss: 2.4362 - accuracy: 0.1444\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3895 - accuracy: 0.1579\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3505 - accuracy: 0.1723\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3152 - accuracy: 0.1860\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2832 - accuracy: 0.2005\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2526 - accuracy: 0.2146\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2229 - accuracy: 0.2280\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1955 - accuracy: 0.2424\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 2.1693 - accuracy: 0.2550\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1440 - accuracy: 0.2676\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1196 - accuracy: 0.2806\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0961 - accuracy: 0.2926\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0740 - accuracy: 0.3026\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0528 - accuracy: 0.3153\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0332 - accuracy: 0.3250\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0126 - accuracy: 0.3373\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.9935 - accuracy: 0.3463\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9755 - accuracy: 0.3558\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.9579 - accuracy: 0.3640\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.9400 - accuracy: 0.3742\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.9237 - accuracy: 0.3820\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 1.9069 - accuracy: 0.3906\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 4s 105us/step - loss: 1.8915 - accuracy: 0.3988\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 4s 93us/step - loss: 1.8748 - accuracy: 0.4083\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 4s 99us/step - loss: 1.8596 - accuracy: 0.4142\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 5s 125us/step - loss: 1.8434 - accuracy: 0.4226\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 4s 105us/step - loss: 1.8290 - accuracy: 0.4305\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 4s 107us/step - loss: 1.8142 - accuracy: 0.4374\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 1.7995 - accuracy: 0.4440\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 4s 103us/step - loss: 1.7847 - accuracy: 0.4520\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 4s 93us/step - loss: 1.7708 - accuracy: 0.4580\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 4s 99us/step - loss: 1.7563 - accuracy: 0.4636\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 1.7420 - accuracy: 0.4699\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.7276 - accuracy: 0.4756\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.7143 - accuracy: 0.4830\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.7006 - accuracy: 0.4879\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.6866 - accuracy: 0.4940\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.6733 - accuracy: 0.4991\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.6600 - accuracy: 0.5070\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.6462 - accuracy: 0.5123\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 1.6340 - accuracy: 0.5166\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.6207 - accuracy: 0.5227\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.6072 - accuracy: 0.5276\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.5949 - accuracy: 0.5343\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.5820 - accuracy: 0.5394\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 1.5694 - accuracy: 0.5419\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 1.5574 - accuracy: 0.5485\n",
      "Try 5/100: Best_val_acc: [1.5576485532124837, 0.550428569316864], lr: 0.00031479821519188805, Lambda: 0.0030098960180125023\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 149us/step - loss: 2.7396 - accuracy: 0.1012\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 2.6796 - accuracy: 0.1064\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.6277 - accuracy: 0.1126\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.5841 - accuracy: 0.1171\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.5431 - accuracy: 0.1233\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 2.5074 - accuracy: 0.1283\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 2.4740 - accuracy: 0.1337\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.4432 - accuracy: 0.1417\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.4165 - accuracy: 0.1478\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3913 - accuracy: 0.1522\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3663 - accuracy: 0.1600\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3442 - accuracy: 0.1665\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3229 - accuracy: 0.1716\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.3015 - accuracy: 0.1791\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2820 - accuracy: 0.1837\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2621 - accuracy: 0.1914\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2439 - accuracy: 0.1972\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2256 - accuracy: 0.2054\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.2077 - accuracy: 0.2115\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1912 - accuracy: 0.2160\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1750 - accuracy: 0.2242\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1592 - accuracy: 0.2317\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1442 - accuracy: 0.2385\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1293 - accuracy: 0.2436\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 4s 83us/step - loss: 2.1153 - accuracy: 0.2509\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1012 - accuracy: 0.2575\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0882 - accuracy: 0.2645\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0749 - accuracy: 0.2687\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0618 - accuracy: 0.2761\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0495 - accuracy: 0.2827\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0368 - accuracy: 0.2890\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 4s 101us/step - loss: 2.0254 - accuracy: 0.2943\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 4s 107us/step - loss: 2.0143 - accuracy: 0.3001\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 2.0026 - accuracy: 0.3050\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 4s 100us/step - loss: 1.9913 - accuracy: 0.3127\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9812 - accuracy: 0.3165\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 1.9704 - accuracy: 0.3221\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9596 - accuracy: 0.3275\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 1.9498 - accuracy: 0.3324\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9401 - accuracy: 0.3377\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9306 - accuracy: 0.3429\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9208 - accuracy: 0.3475\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9112 - accuracy: 0.3525\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.9025 - accuracy: 0.3565\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.8927 - accuracy: 0.3619\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 1.8840 - accuracy: 0.3682\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.8756 - accuracy: 0.3727\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.8669 - accuracy: 0.3754\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.8577 - accuracy: 0.3803\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 1.8498 - accuracy: 0.3845\n",
      "Try 6/100: Best_val_acc: [1.8458032745179676, 0.3879285752773285], lr: 0.00013467856551742925, Lambda: 0.0006055055818524607\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 6s 151us/step - loss: 2.4317 - accuracy: 0.1520\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0426 - accuracy: 0.2985\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 3s 81us/step - loss: 1.8017 - accuracy: 0.4249\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.6040 - accuracy: 0.5139\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.4402 - accuracy: 0.5775\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 1.3028 - accuracy: 0.6199\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.1906 - accuracy: 0.6521\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 1.1021 - accuracy: 0.6767\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 81us/step - loss: 1.0268 - accuracy: 0.6975\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 3s 82us/step - loss: 0.9686 - accuracy: 0.7116\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.9135 - accuracy: 0.7283\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.8755 - accuracy: 0.7396\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.8333 - accuracy: 0.7492\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 4s 90us/step - loss: 0.7977 - accuracy: 0.7618\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.7723 - accuracy: 0.7692\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.7427 - accuracy: 0.7783\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.7169 - accuracy: 0.7865\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 4s 93us/step - loss: 0.6946 - accuracy: 0.7936\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.6747 - accuracy: 0.7982\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 4s 92us/step - loss: 0.6555 - accuracy: 0.8062\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.6391 - accuracy: 0.8110\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 4s 92us/step - loss: 0.6220 - accuracy: 0.8165\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.6036 - accuracy: 0.8230\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.5955 - accuracy: 0.8257\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.5738 - accuracy: 0.8333\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.5600 - accuracy: 0.8360\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.5536 - accuracy: 0.8388\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.5353 - accuracy: 0.8447\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.5298 - accuracy: 0.8443\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 0.5167 - accuracy: 0.8507\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.5109 - accuracy: 0.8515\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 0.5020 - accuracy: 0.8543\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4825 - accuracy: 0.8613\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4796 - accuracy: 0.8629\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4703 - accuracy: 0.8649\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4645 - accuracy: 0.8658\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4536 - accuracy: 0.8699\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4449 - accuracy: 0.8746\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4372 - accuracy: 0.8749\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4300 - accuracy: 0.8783\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4244 - accuracy: 0.8799\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4206 - accuracy: 0.8816\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4190 - accuracy: 0.8821\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 0.4042 - accuracy: 0.8882\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3976 - accuracy: 0.8874\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3872 - accuracy: 0.8924\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3902 - accuracy: 0.8911\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3852 - accuracy: 0.8927\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 0.3788 - accuracy: 0.8953\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 4s 84us/step - loss: 0.3837 - accuracy: 0.8931\n",
      "Try 7/100: Best_val_acc: [0.6460627020767757, 0.7977856993675232], lr: 0.004617948074234781, Lambda: 0.0006390939893715981\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 7s 157us/step - loss: 2.7417 - accuracy: 0.1145\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 2.5416 - accuracy: 0.1541\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 2.4194 - accuracy: 0.1938\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 3s 77us/step - loss: 2.3290 - accuracy: 0.2360\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 2.2507 - accuracy: 0.2738\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 2.1828 - accuracy: 0.3073\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.1192 - accuracy: 0.3402\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0613 - accuracy: 0.3672\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3s 83us/step - loss: 2.0068 - accuracy: 0.3955\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.9551 - accuracy: 0.4209\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.9052 - accuracy: 0.4435\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.8579 - accuracy: 0.4636\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.8128 - accuracy: 0.4869\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.7696 - accuracy: 0.5054\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.7287 - accuracy: 0.5220\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 4s 88us/step - loss: 1.6883 - accuracy: 0.5398\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.6495 - accuracy: 0.5541\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.6144 - accuracy: 0.5683\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.5790 - accuracy: 0.5812\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.5464 - accuracy: 0.5944\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.5161 - accuracy: 0.6033\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.4865 - accuracy: 0.6143\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.4583 - accuracy: 0.6238\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 4s 96us/step - loss: 1.4325 - accuracy: 0.6330\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 4s 91us/step - loss: 1.4073 - accuracy: 0.6405\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 4s 88us/step - loss: 1.3843 - accuracy: 0.6480\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 4s 86us/step - loss: 1.3612 - accuracy: 0.6545\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 4s 87us/step - loss: 1.3395 - accuracy: 0.6596\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42000/42000 [==============================] - 1102s 26ms/step - loss: 1.3194 - accuracy: 0.6655\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 1.2999 - accuracy: 0.6713\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 4s 85us/step - loss: 1.2824 - accuracy: 0.6763\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 4s 88us/step - loss: 1.2635 - accuracy: 0.6809\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 1.2472 - accuracy: 0.6862\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 3s 71us/step - loss: 1.2299 - accuracy: 0.6911\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 1.2156 - accuracy: 0.6964\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 1.2010 - accuracy: 0.6991\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 1.1864 - accuracy: 0.7030\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s 66us/step - loss: 1.1720 - accuracy: 0.7061\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.1597 - accuracy: 0.7114\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 1.1471 - accuracy: 0.7151\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 6s 140us/step - loss: 1.1333 - accuracy: 0.7191\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 9s 220us/step - loss: 1.1227 - accuracy: 0.7209\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 9s 217us/step - loss: 1.1104 - accuracy: 0.7232\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 9s 223us/step - loss: 1.0989 - accuracy: 0.7270\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 9s 220us/step - loss: 1.0894 - accuracy: 0.7295\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 9s 219us/step - loss: 1.0790 - accuracy: 0.7316\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 9s 218us/step - loss: 1.0687 - accuracy: 0.7356\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 9s 218us/step - loss: 1.0582 - accuracy: 0.7388\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 9s 219us/step - loss: 1.0485 - accuracy: 0.7422\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 9s 225us/step - loss: 1.0388 - accuracy: 0.7443\n",
      "Try 8/100: Best_val_acc: [1.0485013680685134, 0.7399285435676575], lr: 0.0009958264356439864, Lambda: 0.009271974211123466\n",
      "\n",
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 19s 448us/step - loss: 1.9834 - accuracy: 0.3177\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 9s 219us/step - loss: 1.2308 - accuracy: 0.6119\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 9s 222us/step - loss: 0.9499 - accuracy: 0.7058\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 9s 220us/step - loss: 0.8394 - accuracy: 0.7430\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 9s 219us/step - loss: 0.7405 - accuracy: 0.7755\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 9s 219us/step - loss: 0.6795 - accuracy: 0.7951\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 10s 243us/step - loss: 0.6296 - accuracy: 0.8103\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 10s 233us/step - loss: 0.6003 - accuracy: 0.8200\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 3711s 88ms/step - loss: 0.5637 - accuracy: 0.8327\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 15s 348us/step - loss: 0.5346 - accuracy: 0.8412\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 11s 253us/step - loss: 0.5008 - accuracy: 0.8529\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 11s 263us/step - loss: 0.4889 - accuracy: 0.8550\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 10s 247us/step - loss: 0.4697 - accuracy: 0.8613\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 10s 239us/step - loss: 0.4460 - accuracy: 0.8693\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 9s 223us/step - loss: 0.4358 - accuracy: 0.8725\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 11s 267us/step - loss: 0.4261 - accuracy: 0.8754\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 9s 225us/step - loss: 0.4032 - accuracy: 0.8826\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 9s 226us/step - loss: 0.3905 - accuracy: 0.8840\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 8s 180us/step - loss: 0.3715 - accuracy: 0.8923\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 3s 64us/step - loss: 0.3484 - accuracy: 0.8992\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 3s 63us/step - loss: 0.3493 - accuracy: 0.8988\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.3449 - accuracy: 0.8995\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 3s 62us/step - loss: 0.3217 - accuracy: 0.9072\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 3s 63us/step - loss: 0.3018 - accuracy: 0.9149\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.3031 - accuracy: 0.9141\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.2909 - accuracy: 0.9177\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 3s 67us/step - loss: 0.2849 - accuracy: 0.9204\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 3s 68us/step - loss: 0.2734 - accuracy: 0.9222\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 3s 69us/step - loss: 0.2562 - accuracy: 0.9297\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.2675 - accuracy: 0.9248\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 3s 70us/step - loss: 0.2645 - accuracy: 0.9245\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.2492 - accuracy: 0.9311\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 3s 72us/step - loss: 0.2499 - accuracy: 0.9291\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 3s 73us/step - loss: 0.2504 - accuracy: 0.9295\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 0.2346 - accuracy: 0.9356\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 3s 74us/step - loss: 0.2230 - accuracy: 0.9394\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.2156 - accuracy: 0.9412\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.2084 - accuracy: 0.9442\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 3s 75us/step - loss: 0.2020 - accuracy: 0.9457\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.1988 - accuracy: 0.9469\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 3s 76us/step - loss: 0.2062 - accuracy: 0.9429\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 3s 77us/step - loss: 0.2023 - accuracy: 0.9442\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 3s 77us/step - loss: 0.1931 - accuracy: 0.9476\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.1905 - accuracy: 0.9494\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.1812 - accuracy: 0.9509\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.1758 - accuracy: 0.9541\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 3s 78us/step - loss: 0.1756 - accuracy: 0.9538\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.1713 - accuracy: 0.9546\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 3s 79us/step - loss: 0.1784 - accuracy: 0.9518\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 3s 80us/step - loss: 0.1680 - accuracy: 0.9563\n",
      "Try 9/100: Best_val_acc: [0.5914877801111766, 0.8314999938011169], lr: 0.05182438168879829, Lambda: 0.0007788856290256715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "for k in range(1,10):\n",
    "    lr = math.pow(10, np.random.uniform(-4.0, -1.0))\n",
    "    Lambda = math.pow(10, np.random.uniform(-4,-2))\n",
    "    best_acc = train_and_test_loop(50, lr, Lambda, False)\n",
    "    print(\"Try {0}/{1}: Best_val_acc: {2}, lr: {3}, Lambda: {4}\\n\".format(k, 100, best_acc, lr, Lambda))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Best Accuracy with learning rate 0.05 and L2 regulariser 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "42000/42000 [==============================] - 2s 46us/step - loss: 2.3292 - accuracy: 0.1038\n",
      "Epoch 2/50\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 2.3024 - accuracy: 0.1244\n",
      "Epoch 3/50\n",
      "42000/42000 [==============================] - 1s 32us/step - loss: 2.2654 - accuracy: 0.1562\n",
      "Epoch 4/50\n",
      "42000/42000 [==============================] - 1s 35us/step - loss: 2.1517 - accuracy: 0.1996\n",
      "Epoch 5/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 2.0925 - accuracy: 0.2180\n",
      "Epoch 6/50\n",
      "42000/42000 [==============================] - 1s 32us/step - loss: 1.8814 - accuracy: 0.3103\n",
      "Epoch 7/50\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9448 - accuracy: 0.2813\n",
      "Epoch 8/50\n",
      "42000/42000 [==============================] - 1s 23us/step - loss: 1.9789 - accuracy: 0.2796\n",
      "Epoch 9/50\n",
      "42000/42000 [==============================] - 1s 35us/step - loss: 1.8466 - accuracy: 0.3396\n",
      "Epoch 10/50\n",
      "42000/42000 [==============================] - 1s 33us/step - loss: 1.6561 - accuracy: 0.4114\n",
      "Epoch 11/50\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 1.5200 - accuracy: 0.4764\n",
      "Epoch 12/50\n",
      "42000/42000 [==============================] - 2s 40us/step - loss: 1.5429 - accuracy: 0.4677\n",
      "Epoch 13/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 1.4054 - accuracy: 0.5207\n",
      "Epoch 14/50\n",
      "42000/42000 [==============================] - 1s 30us/step - loss: 1.3498 - accuracy: 0.5452\n",
      "Epoch 15/50\n",
      "42000/42000 [==============================] - 1s 25us/step - loss: 1.2979 - accuracy: 0.5656\n",
      "Epoch 16/50\n",
      "42000/42000 [==============================] - 1s 25us/step - loss: 1.2974 - accuracy: 0.5718\n",
      "Epoch 17/50\n",
      "42000/42000 [==============================] - 2s 39us/step - loss: 1.2364 - accuracy: 0.5928\n",
      "Epoch 18/50\n",
      "42000/42000 [==============================] - 2s 37us/step - loss: 1.1785 - accuracy: 0.6193\n",
      "Epoch 19/50\n",
      "42000/42000 [==============================] - 2s 37us/step - loss: 1.1162 - accuracy: 0.6453\n",
      "Epoch 20/50\n",
      "42000/42000 [==============================] - 2s 36us/step - loss: 1.0606 - accuracy: 0.6663\n",
      "Epoch 21/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 1.0642 - accuracy: 0.6643\n",
      "Epoch 22/50\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 1.0643 - accuracy: 0.6656\n",
      "Epoch 23/50\n",
      "42000/42000 [==============================] - 1s 27us/step - loss: 1.0133 - accuracy: 0.6824\n",
      "Epoch 24/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 1.0120 - accuracy: 0.6833\n",
      "Epoch 25/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.9841 - accuracy: 0.6925\n",
      "Epoch 26/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.9622 - accuracy: 0.7003\n",
      "Epoch 27/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.9288 - accuracy: 0.7092\n",
      "Epoch 28/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8853 - accuracy: 0.7256\n",
      "Epoch 29/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8814 - accuracy: 0.7260\n",
      "Epoch 30/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8657 - accuracy: 0.7319\n",
      "Epoch 31/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8425 - accuracy: 0.7377\n",
      "Epoch 32/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8339 - accuracy: 0.7400\n",
      "Epoch 33/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8502 - accuracy: 0.7341\n",
      "Epoch 34/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8548 - accuracy: 0.7327\n",
      "Epoch 35/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8225 - accuracy: 0.7443\n",
      "Epoch 36/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.8009 - accuracy: 0.7508\n",
      "Epoch 37/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.7878 - accuracy: 0.7567\n",
      "Epoch 38/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.7830 - accuracy: 0.7565\n",
      "Epoch 39/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7768 - accuracy: 0.7587\n",
      "Epoch 40/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7622 - accuracy: 0.7636\n",
      "Epoch 41/50\n",
      "42000/42000 [==============================] - 1s 28us/step - loss: 0.7858 - accuracy: 0.7538\n",
      "Epoch 42/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7474 - accuracy: 0.7670\n",
      "Epoch 43/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7367 - accuracy: 0.7712\n",
      "Epoch 44/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7285 - accuracy: 0.7741\n",
      "Epoch 45/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7188 - accuracy: 0.7768\n",
      "Epoch 46/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7201 - accuracy: 0.7773\n",
      "Epoch 47/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7239 - accuracy: 0.7745\n",
      "Epoch 48/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.7236 - accuracy: 0.7730\n",
      "Epoch 49/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.6919 - accuracy: 0.7855\n",
      "Epoch 50/50\n",
      "42000/42000 [==============================] - 1s 29us/step - loss: 0.6776 - accuracy: 0.7924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x17ccd0e10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Lambda = 0.0008\n",
    "learning_rate = 0.05\n",
    "tf.reset_default_graph()\n",
    "model = Sequential()\n",
    "    \n",
    "model.add(Dense(200, input_shape = (1024, ), kernel_initializer='he_normal'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(100, kernel_initializer='he_normal'))\n",
    "#model.add(BatchNormalization()) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(60, kernel_initializer='he_normal'))\n",
    "#model.add(BatchNormalization()) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(30, kernel_initializer='he_normal'))\n",
    "#model.add(BatchNormalization()) \n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10, kernel_initializer='he_normal', kernel_regularizer=regularizers.l2(Lambda)))\n",
    "model.add(Activation('softmax'))\n",
    "    \n",
    "sgd = optimizers.SGD(lr=learning_rate, decay=1e-6, momentum=0.9)\n",
    "# Compile model\n",
    "model.compile(optimizer=sgd,loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "# Fit the model\n",
    "model.fit(X_train, y_train1, epochs=50, batch_size=1000, verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.7702777981758118\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test1, verbose=0)\n",
    "print('Test accuracy: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Print the classification accuracy metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "[0.7572125926017761, 0.7702777981758118]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)\n",
    "print(result)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               205000    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 60)                6060      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                1830      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 233,300\n",
      "Trainable params: 233,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
